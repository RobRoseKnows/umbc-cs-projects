\documentclass[12pt]{article}


\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{biblatex}
\usepackage{lipsum}
\usepackage{graphicx}

\bibliography{references.bib}

\title{Analysis of FAFSA completion rates and income in Maryland}


\author{
  Robert P Rose \\
  Department of Computer Science\\
  University of Maryland, Baltimore County\\
  Baltimore, MD 21250 \\
  \texttt{robrose2@umbc.edu} \\
  %% examples of more authors
   \And
  Ujjwal Rehani \\
  Department of Computer Science\\
  University of Maryland, Baltimore County\\
  Baltimore, MD 21250 \\
  \texttt{urehani1@umbc.edu} \\
}

\begin{document}
\maketitle

\begin{abstract}
In this paper we begin by processing and analyzing Free Application for Federal
Student Aid (FAFSA) completion and submission rates in Maryland. We then compared them to 
general statistics about schools taken from the National Center for Education 
Statistics database and with Maryland median income information on a 
county-by-county level. We predicted median income for the observation years using 
simple linear regression and attempt prediction of various FAFSA datapoints using 
varied machine and statistical learning methods. \\
\end{abstract}

\section{Introduction}
For our data science project, we chose to explore data outside the Open Baltimore
data library, as we found that it did not have the most interesting datasets. It
seemed that most of the analysis we could do with Open Baltimore was just crime
statistics analysis, which is a saturated field and full of misleading and 
loaded analysis.\cite{weatherburn2011} \\

Our first proposal was to use hospital location data and traffic accident records
to analyze if proximity to a trauma center increases someone's chance of survival.
Unfortunately it seemed that the information on Data.gov surrounding traffic
accidents was taken at the scene of the accident, and didn't provide long term
outcomes. As a result, any correlation we could find in the data would likely be
simply coincidence or the result of some interference variable. \\

We eventually chose data on FAFSA completion and submission rates, located from
Data.gov.\cite{fafsa2019} We choose to mix this data with Maryland county-level
median income  data and data about each school from the National Center for 
Education Statistics.\cite{nces2019} We limited the data from NCES to schools with
12th grades only, as lower grades typically don't complete FAFSAs. These datasets 
were joined on the school name and the county name. We had to do some 
preprocessing on the school names and city names in order to get them to join 
however. We chose to limit our analysis to Maryland in order to not have a 
overbearing amount of data from the entire country. Additionally, we had to use 
some linear regression to model the incomes for 2017, 2018 and 2019, as our source 
data only went up to 2016.\\

To conclude, we attempted to predict our target variables (FAFSA completion and
submission rates) using the LightGBM machine learning library.\cite{lightgbm2019}
We did sixteen different predictions. This was necessary as there were many ways
to prepare the target variables, such as by percentage vs. by raw numbers, by FAFSA
submissions vs. FAFSA completions and by 2018 data and 2019 data. Additionally,
we repeated the predictions again using only the most important predictor variables,
which showed some nominal improvements.

\section{Exploration of School Data}
There were numerous predictor variables that arose from the dataset. In our
exploration of the data, we printed descriptive statistics for each variable,
plotted correlations between each variable and also graphed the distributions 
of the categorical variables. \\

The most self explanatory variables are \texttt{Charter} and \texttt{Magnet}, 
which labeled if each school was a charter or magnet school, respectively. 
Charter schools receive government funding but operate independently of 
the established state school system in which it is located. Magnet schools 
are public schools with specialized courses or curricula. The distribution of
these variables can be seen in Figure \ref{fig:charter} and Figure \ref{fig:magnet}, 
respectively. \\

One interesting fact that we stumbled upon accidentally was 
that the majority of charter schools in Maryland are in Baltimore City. 
We discovered this when we realized that Baltimore City wasn't being properly 
merged in our pipeline, as one data source listed it as "Baltimore city" and another
listed it as "Baltimore City". As a result, it was necessary to add additional 
steps to our pipeline in order to normalize those values. \\

\begin{figure}[!htb]
  \centering
  \includegraphics[width=90mm]{charter_graph.png}
  \caption{Distribution of Charter Schools}
  \label{fig:charter}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=90mm]{magnet_graph.png}
  \caption{Distribution of Magnet Schools}
  \label{fig:magnet}
\end{figure}

Some of the other predictor variables were not as straightforward however. The
predictors \texttt{Title\_1\_School\_Wide} and \texttt{Title\_I\_School},
for example confused us quite a bit as we were unable to determine what the 
difference between them was supposed to be. While Title I schools have a student
base schools have a student population that is lower-income and they are provided 
with Title I  funding in order to help those who are, or at risk of, falling behind, 
aiming to bridge the gap between low-income students and other students, we
were unable to determine what Title I School-wide meant in our research. They 
were both found in the NCES dataset as separate columns, so they weren't just a 
merging error, and they both contained separate data.\cite{nces2019} The school-wide 
column contained some missing data, which was denoted by a cross symbol in the 
NCES dataset, which further compounded the confusion surrounding it. The
other column only contained "Yes" and "No" however, and was fairly easily understood.
You can see the distribution of the two columns in Figure \ref{fig:title_1_wide}
and Figure \ref{fig:title_i} respectively.\\

Another interesting fact we discovered as a result of our pipeline problems with
Baltimore City is that a majority of Baltimore City schools are Title I Schools
and the majority of schools in Maryland outside of Baltimore City are not Title
I schools. This was not terribly surprising giving the poverty found in Baltimore
City, but it was a notable discovery that resulted from an accident.\\

\begin{figure}[!htb]
  \centering
  \includegraphics[width=100mm]{title_1_wide_graph.png}
  \caption{Distribution of Title 1 School Wide.}
  \label{fig:title_1_wide}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=100mm]{title_i_graph.png}
  \caption{Distribution of Title I Schools.}
  \label{fig:title_i}
\end{figure}

The final two predictor variables from the school data we explored were \texttt{Locale}
and \texttt{Locale\_Code}. At first we thought these data points were conveying the
same information considering how similar their distributions were, as you can see in
Figure \ref{fig:locale} and Figure \ref{fig:locale_code}, respectively. However when
we attempted to get the correlation between the two variables to confirm that, we found
that the variables were not all that correlated. This surprised us, as we expected data
points with such similar distributions to be correlated.\\

Locale describes what kind of environment the school is in, whether it's in a Large Suburb,
a Small City, a Distant Town, etc. The most common locales were "Suburb: Large", by a long shot
and "City: Large" and "Rural: Fringe" neck and neck for second. There were over twice as many
schools in Large Suburbs as there were in Large Cities, which says a lot about Maryland's land
use. We're not quite sure what Locale Code means however, as the data source was not well
documented. We did conclude that it was a categorical variable however, and not a continuous 
one.\\

\begin{figure}[!htb]
  \centering
  \includegraphics[width=120mm]{locale_graph.png}
  \caption{Distribution of Locales}
  \label{fig:locale}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=100mm]{locale_code_graph.png}
  \caption{Distribution of Locale Code}
  \label{fig:locale_code}
\end{figure}

Finally, there was some data on school districts and school counties. We needed the
school counties in order to merge the FAFSA dataframe with the income dataframe, as
we were only able to find median income data on a per county basis. Additionally,
school districts and school counties were highly correlated, so we ended up dropping
the school districts. While in other states the school districts aren't necessarily
the same as the counties the schools are in, in Maryland that is almost always the
case, save for some private schools and charter schools.\\

The distribution of counties can be seen in Figure \ref{fig:county}. Notably, this is
also when we realized Baltimore City hadn't been merged into the dataframe properly,
as it was notably missing from our graph. This was when we went back to rework part
of our pipeline to fix this error. Notably, the counties with the most number of 
schools are also Maryland's most populous counties. As a reminder, this does only
include schools which include 12th grade, as we wouldn't expect lower grades to
be completing FAFSAs.\\

\begin{figure}[!htb]
  \centering
  \includegraphics[width=130mm]{county_graph.png}
  \caption{Distribution of School Counties}
  \label{fig:county}
\end{figure}


\section{Exploration of FAFSA Data}

The FAFSA Data contained several target columns for us to look at. While it 
provided year-end data for the 2018-2019 year, since we wanted to compare
apples to apples, we chose only to look at the data for April 19, 2018 for the
2018-2019 cycle and April 19, 2019 for the 2019-2020 cycle. The data also provided
statistics on "submissions" and "completions". We assume these signify those who
started a FAFSA application online and those who ended up submitting their FAFSA.
From the descriptive statistics we produced on the dataframe, on average 
submissions and completions were fairly close to one another.\\

Additionally, we needed to do some preprocessing to make sure all the data was
in a numerical format. In order to protect student's privacy, if fewer than five
people would be represented in any column, the column simply listed "<5". We chose
to fill all the "<5" columns with zero, which seemed to be an appropriate placeholder
for the columns. Thankfully there were no cases of dividing by zero when processing
the data, so we didn't need to consider that in our pipeline.\\

At this point in the exploration, we weren't sure if the predictions would be better
with raw student numbers or with a percentage of the total student population.
So we chose to explore both possibilities. We generated percentages submitted out of
total number of students, percentages completed out of the total number of students
and percentages completed out of the amount submitted. We then used the seaborn
plotting library to produce ridge plots comparing the various percentages across the 
2018-2019 cycle and the 2019-2020 cycle, which can be seen in Figure 
\ref{fig:target_perc}. \cite{snsridgeplot2019} \\

\begin{figure}[!htb]
  \centering
  \includegraphics[width=130mm]{cool_density_plot_perc.png}
  \caption{Distribution of Percentage Target Variables}
  \label{fig:target_perc}
\end{figure}

As visible in Figure \ref{fig:target_perc}, the percentage of people submitting a 
FAFSA they completed is heavily skewed towards 100\%. We assume that this is 
because most people who start completing a FAFSA end up submitting it. The distribution
of the percentage of total students who submitted or completed a FAFSA was roughly
equal for each year however. We conclude that this is because most schools have similar
class sizes every year and most of the schools we analyized were four-year schools, 
as seen in Figure \ref{fig:grades} so roughly 25\% of their total student population would be 
completing or submitting a FAFSA every year. Additionally, it is notable that the percentages 
were normally distributed. This is somewhat expected with a sample of this size, and the 
kernel density plots do exacerbate the apparent distribution but it is notable nonetheless.\\

\begin{figure}[!htb]
  \centering
  \includegraphics[width=100mm]{grades_graph.png}
  \caption{Distribution of Number of Grades in School}
  \label{fig:grades}
\end{figure}

The second series of ridge plots we produced were for the raw number of students
who completed or submitted a FAFSA for the 2018-2019 or 2019-2020 cycles. For this
graph however, we chose to also include the June 2018 and December 2018 statistics
in order to get a better idea of the structure of the data. Unfortunately, the ridge
plots don't tell us much. There wasn't a familiar normal distribution like there was
for the percentages, as schools in Maryland vary in size quite a bit, though schools
are more likely to have fewer students than more students. However the spread was
fairly uniform along a certain interval so they didn't produce terribly interesting
plots, as you can see in Figure \ref{fig:target_raw}.

\begin{figure}[!htb]
  \centering
  \includegraphics[width=130mm]{cool_density_plot_raw.png}
  \caption{Distribution of Raw Target Variables}
  \label{fig:target_raw}
\end{figure}

\section{Exploration of FAFSA and Income Data Combined}
A model that we decided to apply out dataset was the Light GBM model. This a gradient boosting framework that uses tree based learning algorithm. We wanted to isolate the attributes, in addition to income, that were the most important in determining FAFSA completions/submissions percentages and then remove the ones we did not need based on the results of the model. After training the model several times, a graph showing the importance of each attribute was compiled. The most important attributes ended up being Title-I-School, Income-2017, Income-2018, Income-2019, Students,Student-Teacher-Ratio, Teachers,Locale-Code-21, Title-1-School-Wide-, Title-1-School-Wide-Yes, and Magnet. The RMSE is quite low which indicated a good level of accuracy. The average RMSE was 3.56 percent which was within one standard deviation of the mean for all the statistics we described above for percentage.

We then repeated the above process, but this time with the only important features we derived from above. For the model dealing with 2019 completed applications, there was not much improvement. Income levels had the highest degree of importance along with number of teachers and students. Interestingly, Locale code 21 had a considerable amount of importance, but we are still unsure of what it actually represents. The 2018 completed applications model showed similar results to the previous one. When looking at the 18/19 submitted applications models, there was a slight improvement on average RMSE, but the important features remained the same as in all of the previous models.\\


Insert images here

The next set of models we created utilized raw numbers from the data rather than percentages. We predicted that the number of students will likely be the most exploited for every run, as the algorithm not only has to predict how many students will interact with FAFSA but also how many students the school has as a whole. It's also possible the model will heavily use the Grades feature, which was engineered by subtracting Low-Grade from High-Grade. After running the model, students was indeed the top predictor for FAFSA applications as hypothesized earlier.

\begin{figure}[!htb]
  \centering
  \includegraphics[width=100mm, scale=1]{RawSubmitted19.PNG}
  \caption{All Features for Submitted 2019 Applications(Raw)}
  \label{fig:feature_importance}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=100mm, scale=1]{RawCompleted19.PNG}
  \caption{All Features for Completed 2019 Applications(Raw)}
  \label{fig:feature_importance}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=100mm, scale=1]{RawSubmitted18.PNG}
  \caption{All Features for Submitted 2018 Application(Raw)}
  \label{fig:feature_importance}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=100mm, scale=1]{RawCompleted18.PNG}
  \caption{All Features for Completed 2018 Applications(Raw)}
  \label{fig:feature_importance}
\end{figure}


As we did previously we repeated the the process, but this time with the top important features that the previous model determined. The top features for the raw data were Title-I-School, Income-2017, Income-2018, Students, Student-Teacher-Ratio, Teachers, Locale-Suburb: Large,Locale-Code-21, Title-1-School-Wide-,Title-1-School-Wide-Yes, Magnet, and City-Baltimore.\\

Surprisingly City-Baltimore completely dropped off the map when we only used the top features, while Locale-Suburb: Large gained a couple of spots. This actually did slightly worse that the all features, though is still within the same ballpark.

\begin{figure}[!htb]
  \centering
  \includegraphics[width=100mm, scale=1]{RawTopSubmitted19.PNG}
  \caption{Top Features for Submitted 2019 Applications(Raw)}
  \label{fig:feature_importance}
\end{figure}

Not unexpected to see the Locale-Code-41 drop off the top features list when we limit the number of features. Though it is quite weird to see Locale-Code-21, which was rather high previously drop all the way down.

\begin{figure}[!htb]
  \centering
  \includegraphics[width=100mm, scale=1]{RawTopCompleted19.PNG}
  \caption{Top Features for Completed 2019 Applications(Raw)}
  \label{fig:feature_importance}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=100mm, scale=1]{RawTopSubmitted18.PNG}
  \caption{Top Features for Submitted 2018 Application(Raw)}
  \label{fig:feature_importance}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=100mm, scale=1]{RawTopCompleted18.PNG}
  \caption{Top Features for Completed 2018 Applications(Raw)}
  \label{fig:feature_importance}
\end{figure}


\section{Conclusion}


\printbibliography
% \bibliographystyle{unsrt}  
% \bibliography{references}  %%% Remove comment to use the external .bib file (using bibtex).
%%% and comment out the ``thebibliography'' section.


%%% Comment out this section when you \bibliography{references} is enabled.

\end{document}
